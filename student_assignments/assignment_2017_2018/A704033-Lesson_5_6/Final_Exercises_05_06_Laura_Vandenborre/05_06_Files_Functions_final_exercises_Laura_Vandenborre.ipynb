{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will learn how to work with files on disk, and introduce some important concepts along the way: the use of external libraries, character encodings and file paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by *Think Python* by Allen B. Downey (http://thinkpython.com), *Introduction to Programming Using Python* by Y. Liang (Pearson, 2013). Some exercises below have been taken from: http://www.ling.gu.se/~lager/python_exercises.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 1: go to Project Gutenberg (http://www.gutenberg.org) and download your favorite out-of-copyright book in plain text format. Make a frequency dictionary of the words in the novel. Sort the words in the dictionary by increasing frequency and write it to a text file called `frequencies.txt`. Make sure your program ignores capitalization. Find out how you can sort a dictionary by value -- there are several ways of doing this, search the web in order to get some help. As a bonus exercise, add code so that the frequency dictionary ignores punctuation (hint: check out `string.punctuation` to get all punctuation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import codecs\n",
    "f = codecs.open(\"data/gullivers_travels.txt\", \"r\", \"utf-8\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "no_punct = text.translate(translator)\n",
    "words = no_punct.lower().split()\n",
    "\n",
    "freq_dict = {}\n",
    "for word in words:\n",
    "    if word in freq_dict:\n",
    "        freq_dict[word] += 1\n",
    "    else:\n",
    "        freq_dict[word] = 1\n",
    "\n",
    "word_list = freq_dict.items()\n",
    "sorted_list = sorted(word_list, key=lambda x: x[1])\n",
    "print(sorted_list)\n",
    "\n",
    "f = codecs.open(\"data/frequencies.txt\", \"w\", \"utf-8\")\n",
    "for t in sorted_list:\n",
    "    line = \": \".join(str(x) for x in t)\n",
    "    f.write(\"\\n\" + \", \" + line)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 2: rewrite the novel in the previous exercise, by replacing the name of the principal character in the novel by your own name. (Use the `replace()` function for this.) Write the new version of novel to a file called `starring_me.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "f = codecs.open(\"data/gullivers_travels.txt\", \"r\", \"utf-8\")\n",
    "text = f.read()\n",
    "f.close()\n",
    "\n",
    "starring_me = text.replace(\"Gulliver\", \"Vandenborre\").replace(\"Lemuel\", \"Laura\").replace(\"GULLIVER\", \"VANDENBORRE\")\n",
    "print(starring_me)\n",
    "\n",
    "f = codecs.open(\"data/starring_me.txt\", \"w\", \"utf-8\")\n",
    "f.write(starring_me)\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 3: Write a program that takes a text file (e.g. `filename.txt`) and creates a new text file (e.g. `filename_numbered.txt`) in which all the lines from the original file are numbered from 1 to n (where n is the number of lines in the file), i.e. prepend the number and a space to each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/filename.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-541caa815b3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/filename.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#numbered_list = text.readlines()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, buffering)\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0;31m# Force opening of the file in binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/filename.txt'"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "f = codecs.open(\"data/filename.txt\", \"r\", \"utf-8\")\n",
    "text = f.read()\n",
    "#numbered_list = text.readlines()\n",
    "n = 1\n",
    "for line in numbered_list:\n",
    "    line_number = (str(n) + \"\\t\" + line)\n",
    "    n += 1\n",
    "    print(line_number)\n",
    "f.close()\n",
    "    \n",
    "f = codecs.open(\"data/jabberwocky_numbered.txt\", \"w\", \"utf-8\")\n",
    "f.write(line_number)\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Advanced bonus exercise for if you feel like trying something crazy: a *sentence splitter* is a program capable of splitting a text into sentences. The standard set of heuristics for sentence splitting includes (but isn't limited to) the following rules: Sentence boundaries occur at one of \".\" (periods), \"?\" or \"!\", except that:\n",
    "\n",
    "> - Periods followed by whitespace followed by a lowercase letter are not sentence boundaries.\n",
    "> - Periods followed by a digit with no intervening whitespace are not sentence boundaries.\n",
    "> - Periods followed by whitespace and then an uppercase letter, but preceded by any of a short list of titles are not sentence boundaries. Sample titles include Mr., Mrs., Dr., and so on.\n",
    "> - Periods internal to a sequence of letters with no adjacent whitespace are not sentence boundaries, such as in www.aptex.com or e.g.\n",
    "> - Periods followed by certain kinds of punctuation (notably comma and more periods) are probably not sentence boundaries.\n",
    "\n",
    "You might want to check out string functions, like `.islower()` and `.isalpha()` in the official Python documentation online. Your task here is to write a function that given the name of a text file is able to write its content with each sentence on a separate line to a new file whose name is also passed as an argument to the function. The function itself should return a list of sentences. Test your program with the following short text: `\"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.\"` The result written to the new file should be:\n",
    "\n",
    "Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it.\n",
    "\n",
    "Did he mind?\n",
    "\n",
    "Adam Jones Jr. thinks he didn't.\n",
    "\n",
    "In any case, this isn't true...\n",
    "\n",
    "Well, with a probability of .9 it isn't.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "You've reached the end of Chapter 5! You can safely ignore the code below, it's only there to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you make the exercises below, don't write your code in the IPython notebook anymore but write in a separate file and run them from the command line!**\n",
    "\n",
    "Inspired by *Think Python* by Allen B. Downey (http://thinkpython.com), *Introduction to Programming Using Python* by Y. Liang (Pearson, 2013). Some exercises below have been taken from: http://www.ling.gu.se/~lager/python_exercises.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dice.py`: write a script that rolls a dice every time you run it, by generating and printing a random integer between 1 and 6! You can import functionality for doing this via `random.randint()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  `arithmetic.py`: define a function add() and a function multiply() that sums and multiplies (respectively) all the numbers in a list of numbers. For example, add([1, 2, 3, 4]) should return 10, and multiply([1, 2, 3, 4]) should return 24.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  `anagram.py`: two words are anagrams if you can rearrange the letters from one to spell the other. Write a function called is_anagram that takes two strings and returns True if they are anagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  `hapax1.py`: a *hapax legomenon* (often abbreviated to hapax) is a word which occurs only once in either the written record of a language, the works of an author, or in a single text. Define a function `legomena` that given the filename of a text will return a list of all its hapax legomena. Make sure your program ignores capitalization as well as punctuation (hint: check out `string.punctuation` online!). Try out the function on your Gutenberg book from the previous Chapter. For simplicity, make sure your Gutenberg file is in the same directory as your hapax script, so that you can just use the file's name as a relative path. Alternatively, you can use an absolute path to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hapax2.py`: copy `hapax1.py` and try to move well-defined steps from your `legomena` function (reading and cleaning the input text, making a frequency dictionary) into separate functions, which are then called in the `legomena` function. This is called *code refactoring*: splitting multi-step functionality over several functions. This is good practice, and will make the next exercise much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hapax3.py`: copy `hapax2.py` and create two additional functions: one that spots hapax `dislegomena` (words occuring only twice) and one that spots hapax `trislegomena` (words occuring only three times) in a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `calling_hapax.py`: in this standalone script, import the functions from `hapax3.py` and call all three functions from there. Again, try them out on your Gutenberg-file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "You've reached the end of Chapter 6! You can safely ignore the code below, it's only there to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "_joined"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
