{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will learn how to work with files on disk, and introduce some important concepts along the way: the use of external libraries, character encodings and file paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by *Think Python* by Allen B. Downey (http://thinkpython.com), *Introduction to Programming Using Python* by Y. Liang (Pearson, 2013). Some exercises below have been taken from: http://www.ling.gu.se/~lager/python_exercises.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 1: go to Project Gutenberg (http://www.gutenberg.org) and download your favorite out-of-copyright book in plain text format. Make a frequency dictionary of the words in the novel. Sort the words in the dictionary by increasing frequency and write it to a text file called `frequencies.txt`. Make sure your program ignores capitalization. Find out how you can sort a dictionary by value -- there are several ways of doing this, search the web in order to get some help. As a bonus exercise, add code so that the frequency dictionary ignores punctuation (hint: check out `string.punctuation` to get all punctuation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ex. 1: go to Project Gutenberg (http://www.gutenberg.org) and download your favorite out-of-copyright book in plain text format.\n",
    "#  Make a frequency dictionary of the words in the novel.\n",
    "# Sort the words in the dictionary by increasing frequency and write it to a text file called frequencies.txt.\n",
    "#  Make sure your program ignores capitalization.\n",
    "# Find out how you can sort a dictionary by value -- there are several ways of doing this, search the web in order to get some help.\n",
    "#  As a bonus exercise, add code so that the frequency dictionary ignores punctuation\n",
    "#  (hint: check out string.punctuation to get all punctuation).\n",
    "\n",
    "import codecs\n",
    "f= codecs.open (\"ThePictureOfDorianGray.txt\", \"r\",\"utf-8\")\n",
    "t_input = f.read ()\n",
    "f.close()\n",
    "#print (t_input)\n",
    "\n",
    "\n",
    "import re\n",
    "list_tokens_original=re.findall(r\"[\\w']+|[.,!?;]\", t_input.lower())\n",
    "dict_tokens ={} #without punctuation marks, extra spaces: the pure words in lower case.\n",
    "import string\n",
    "#print (string.punctuation)\n",
    "for token in list_tokens_original:\n",
    "    #three possibilities:\n",
    "    # a) new token --> add key, + value 1 to dict\n",
    "    # b) not first occurence --> value += 1\n",
    "    # c) token = punctuation mark --> ignore\n",
    "   if token not in string.punctuation:\n",
    "        if token not in dict_tokens:\n",
    "            dict_tokens[token]=1\n",
    "        elif token in dict_tokens:\n",
    "            dict_tokens[token]= dict_tokens[token]+ 1\n",
    "\n",
    "#print (dict_tokens)\n",
    "#print (len(dict_tokens))\n",
    "\n",
    "# Sort the words in the dictionary by increasing frequency and write it to a text file called frequencies.txt.\n",
    "\n",
    "from collections import OrderedDict\n",
    "sorted_frequency_dictionary = OrderedDict(sorted(dict_tokens.items(), key=lambda x: x[1]))\n",
    "#print ( sorted_frequency_dictionary)\n",
    "\n",
    "f= codecs.open(\"frequencies.txt\",\"w\",\"utf-8\")\n",
    "import json\n",
    "json.dump(sorted_frequency_dictionary,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 2: rewrite the novel in the previous exercise, by replacing the name of the principal character in the novel by your own name. (Use the `replace()` function for this.) Write the new version of novel to a file called `starring_me.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "f= codecs.open(\"ThePictureOfDorianGray.txt\",'r', 'utf-8')\n",
    "t_input = f.read()\n",
    "f.close()\n",
    "\n",
    "f2=codecs.open(\"starring_me.txt\", \"w\", \"utf-8\")\n",
    "f2.write(t_input.replace(\"Dorian\", \"Laura\"))\n",
    "f2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 3: Write a program that takes a text file (e.g. `filename.txt`) and creates a new text file (e.g. `filename_numbered.txt`) in which all the lines from the original file are numbered from 1 to n (where n is the number of lines in the file), i.e. prepend the number and a space to each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#Ex. 3: Write a program that takes a text file (e.g. filename.txt) and creates a new text file (e.g. filename_numbered.txt)\n",
    "#  in which all the lines from the original file are numbered from 1 to n (where n is the number of lines in the file),\n",
    "#  i.e. prepend the number and a space to each line.\n",
    "\n",
    "def numbered_lines(filename_in): #this function generates a new text file (\"filename_numbered.txt\") with all the lines preceded by the line number\n",
    "    import os\n",
    "    base = os.path.basename(filename_in)\n",
    "    base_out = (os.path.splitext(base)[0]) + \"_numbered\" + os.path.splitext(base)[1]\n",
    "    filename_out= os.path._getfullpathname(base_out)\n",
    "\n",
    "    #filename_in_pythonposition = os.path._getfullpathname(base)\n",
    "    #print(filename_in_pythonposition)\n",
    "   # print(filename_out)\n",
    "\n",
    "\n",
    "\n",
    "    with open(filename_in,'r') as program:\n",
    "        l_lines = program.readlines()\n",
    "\n",
    "    with open(filename_out, 'w') as program:\n",
    "        for (number, line) in enumerate(l_lines):\n",
    "            program.write('%d  %s' % (number + 1, line))\n",
    "\n",
    "filename_in=\"ThePictureOfDorianGray.txt\"\n",
    "\n",
    "numbered_lines(filename_in)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Advanced bonus exercise for if you feel like trying something crazy: a *sentence splitter* is a program capable of splitting a text into sentences. The standard set of heuristics for sentence splitting includes (but isn't limited to) the following rules: Sentence boundaries occur at one of \".\" (periods), \"?\" or \"!\", except that:\n",
    "\n",
    "> - Periods followed by whitespace followed by a lowercase letter are not sentence boundaries.\n",
    "> - Periods followed by a digit with no intervening whitespace are not sentence boundaries.\n",
    "> - Periods followed by whitespace and then an uppercase letter, but preceded by any of a short list of titles are not sentence boundaries. Sample titles include Mr., Mrs., Dr., and so on.\n",
    "> - Periods internal to a sequence of letters with no adjacent whitespace are not sentence boundaries, such as in www.aptex.com or e.g.\n",
    "> - Periods followed by certain kinds of punctuation (notably comma and more periods) are probably not sentence boundaries.\n",
    "\n",
    "You might want to check out string functions, like `.islower()` and `.isalpha()` in the official Python documentation online. Your task here is to write a function that given the name of a text file is able to write its content with each sentence on a separate line to a new file whose name is also passed as an argument to the function. The function itself should return a list of sentences. Test your program with the following short text: `\"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.\"` The result written to the new file should be:\n",
    "\n",
    "Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it.\n",
    "\n",
    "Did he mind?\n",
    "\n",
    "Adam Jones Jr. thinks he didn't.\n",
    "\n",
    "In any case, this isn't true...\n",
    "\n",
    "Well, with a probability of .9 it isn't.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "You've reached the end of Chapter 5! You can safely ignore the code below, it's only there to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
