{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5: Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chapter, we will learn how to work with files on disk, and introduce some important concepts along the way: the use of external libraries, character encodings and file paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by *Think Python* by Allen B. Downey (http://thinkpython.com), *Introduction to Programming Using Python* by Y. Liang (Pearson, 2013). Some exercises below have been taken from: http://www.ling.gu.se/~lager/python_exercises.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 1: go to Project Gutenberg (http://www.gutenberg.org) and download your favorite out-of-copyright book in plain text format. Make a frequency dictionary of the words in the novel. Sort the words in the dictionary by increasing frequency and write it to a text file called `frequencies.txt`. Make sure your program ignores capitalization. Find out how you can sort a dictionary by value -- there are several ways of doing this, search the web in order to get some help. As a bonus exercise, add code so that the frequency dictionary ignores punctuation (hint: check out `string.punctuation` to get all punctuation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file...\n",
      "Compiling dictionary... Hang in there, this can take a while...\n",
      "Sorting and exporting...\n",
      "File successfully exported as frequencies.txt\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "from collections import OrderedDict\n",
    "from string import punctuation\n",
    "\n",
    "frequencies = {}\n",
    "counter = -1\n",
    "\n",
    "print(\"Reading file...\")\n",
    "file = codecs.open(\"Data/Autobiography of Benjamin Franklin.txt\",\"r\",\"utf-8\")\n",
    "data = file.read()\n",
    "file.close()\n",
    "\n",
    "print(\"Compiling dictionary... Hang in there, this can take a while...\")\n",
    "words = data.lower().split()\n",
    "\n",
    "# Splitting leading and trailing punctuation so that contractions and hyphenated words remain untouched.\n",
    "for item in words:                      \n",
    "    counter += 1\n",
    "    words[counter] = item.strip(punctuation)  \n",
    "    \n",
    "# I had to make sure to start the counting after the stripping was complete, to avoid miscalculations\n",
    "for stripped in words:                  \n",
    "    if stripped not in frequencies:     \n",
    "        frequencies[stripped] = words.count(stripped)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(\"Sorting and exporting...\")\n",
    "frequencies = OrderedDict(sorted(frequencies.items(), key=lambda t: t[1], reverse=True))    \n",
    "\n",
    "export = codecs.open(\"Data/frequencies.txt\",\"w\",\"utf-8\")\n",
    "\n",
    "for key in frequencies:\n",
    "    export.write(key+\": \"+str(frequencies[key])+\"\\r\\n\")\n",
    "    \n",
    "export.close()\n",
    "print(\"File successfully exported as frequencies.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 2: rewrite the novel in the previous exercise, by replacing the name of the principal character in the novel by your own name. (Use the `replace()` function for this.) Write the new version of novel to a file called `starring_me.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file...\n",
      "replacing main character...\n",
      "successfully exported as starring_me.txt\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "print(\"reading file...\")\n",
    "franklin = codecs.open(\"Data/Autobiography of Benjamin Franklin.txt\",\"r\",\"utf-8\")\n",
    "data = franklin.read()\n",
    "franklin.close()\n",
    "\n",
    "print(\"replacing main character...\")\n",
    "data = data.replace(\"Benjamin\",\"Lode\")\n",
    "data = data.replace(\"BENJAMIN\",\"LODE\")\n",
    "data = data.replace(\"B. Franklin\",\"L. Rosseels\")\n",
    "data = data.replace(\"Franklin\",\"Rosseels\")\n",
    "data = data.replace(\"FRANKLIN\",\"ROSSEELS\")\n",
    "\n",
    "export = codecs.open(\"Data/starring_me.txt\",\"w\",\"utf-8\")\n",
    "export.write(data)\n",
    "export.close()\n",
    "print(\"successfully exported as starring_me.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ex. 3: Write a program that takes a text file (e.g. `filename.txt`) and creates a new text file (e.g. `filename_numbered.txt`) in which all the lines from the original file are numbered from 1 to n (where n is the number of lines in the file), i.e. prepend the number and a space to each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure the file is located in the working directory.\n",
      "Insert the filename: Data/Autobiography of Benjamin Franklin.txt\n",
      "Data/Autobiography of Benjamin Franklin_numbered.txt has been created in the working directory\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import os\n",
    "\n",
    "print(\"Please make sure the file is located in the working directory.\")\n",
    "input_file = input(\"Insert the filename: \")\n",
    "counter = 0\n",
    "\n",
    "original = codecs.open(input_file,\"r\",\"utf-8\")\n",
    "data = original.read()\n",
    "original.close()\n",
    "\n",
    "    \n",
    "output_file = os.path.splitext(input_file)\n",
    "output_file = output_file[0]+\"_numbered\"+str(output_file[1])\n",
    "\n",
    "output = codecs.open(output_file, \"w\", \"utf-8\")\n",
    "\n",
    "numbered = data.split(\"\\r\\n\")\n",
    "for line in numbered:\n",
    "    counter += 1\n",
    "    newline = str(counter)+\" \"+line+\"\\r\\n\"\n",
    "    output.write(newline)\n",
    "\n",
    "output.close()\n",
    "\n",
    "print(output_file+\" has been created in the same directory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Advanced bonus exercise for if you feel like trying something crazy: a *sentence splitter* is a program capable of splitting a text into sentences. The standard set of heuristics for sentence splitting includes (but isn't limited to) the following rules: Sentence boundaries occur at one of \".\" (periods), \"?\" or \"!\", except that:\n",
    "\n",
    "> - Periods followed by whitespace followed by a lowercase letter are not sentence boundaries.\n",
    "> - Periods followed by a digit with no intervening whitespace are not sentence boundaries.\n",
    "> - Periods followed by whitespace and then an uppercase letter, but preceded by any of a short list of titles are not sentence boundaries. Sample titles include Mr., Mrs., Dr., and so on.\n",
    "> - Periods internal to a sequence of letters with no adjacent whitespace are not sentence boundaries, such as in www.aptex.com or e.g.\n",
    "> - Periods followed by certain kinds of punctuation (notably comma and more periods) are probably not sentence boundaries.\n",
    "\n",
    "You might want to check out string functions, like `.islower()` and `.isalpha()` in the official Python documentation online. Your task here is to write a function that given the name of a text file is able to write its content with each sentence on a separate line to a new file whose name is also passed as an argument to the function. The function itself should return a list of sentences. Test your program with the following short text: `\"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.\"` The result written to the new file should be:\n",
    "\n",
    "Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it.\n",
    "\n",
    "Did he mind?\n",
    "\n",
    "Adam Jones Jr. thinks he didn't.\n",
    "\n",
    "In any case, this isn't true...\n",
    "\n",
    "Well, with a probability of .9 it isn't.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input your source file, or leave blank and press enter for the test sentence\n",
      "Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it.\n",
      "Did he mind?\n",
      "Adam Jones Jr. thinks he didn't.\n",
      "In any case, this isn't true...\n",
      "Well, with a probability of .9 it isn't.\n",
      "Your file has been exported to Data/new_file_split.txt\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# text = re.split('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)(\\s|[A-Z].*)',text)\n",
    "# I'd rather use this in real situations, but since this is an exercise...\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "source = input(\"input your source file, or leave blank and press enter for the test sentence\")\n",
    "\n",
    "# input handling\n",
    "if source:\n",
    "    original = codecs.open(source,\"r\",\"utf-8\")\n",
    "    text = original.read()\n",
    "    original.close()\n",
    "else:\n",
    "    source = \"Data/new_file.txt\"\n",
    "    text = \"Mr. Smith bought cheapsite.com for 1.5 million dollars, i.e. he paid a lot for it. Did he mind? Adam Jones Jr. thinks he didn't. In any case, this isn't true... Well, with a probability of .9 it isn't.\"\n",
    "\n",
    "charlist = []\n",
    "titles = [\"Mr.\",\"Mrs.\",\"Dr.\",\"Drs.\",\"Jr.\",\" Sr.\"]\n",
    "pos = -1\n",
    "\n",
    "# splitting, replacing breaks with markers, then rejoining\n",
    "for char in text:\n",
    "    charlist.append(char)\n",
    "for item in charlist:\n",
    "    pos += 1\n",
    "    try:\n",
    "        if item == \"!\" and charlist[pos + 1] == \" \":    #!+space -> break\n",
    "            charlist[pos + 1] = \"\\w\"\n",
    "        elif item == \"?\" and charlist[pos + 1] == \" \":    #?+space -> break\n",
    "            charlist[pos + 1] = \"\\w\"\n",
    "        elif item == \".\" and charlist[pos + 1] == \" \" and charlist[pos + 2].isupper(): #.+space+capital -> break\n",
    "            charlist[pos + 1] = \"\\w\"                         \n",
    "        else:\n",
    "            pass                                    # I'm replacing pos+1 to avoid spaces before the sentences\n",
    "    except IndexError:   # prevents error when nearing end of the list, it's a sentence ending anyways.\n",
    "        pass \n",
    "text = \"\".join(charlist)\n",
    "\n",
    "# rolling back actions on titles\n",
    "for title in titles:\n",
    "    while title+\"\\w\" in text:\n",
    "        text = text.replace(title+\"\\w\",title+\" \")\n",
    "\n",
    "#output path\n",
    "output_file = os.path.splitext(source)\n",
    "output_file = output_file[0]+\"_split\"+str(output_file[1])\n",
    "\n",
    "#output\n",
    "output = codecs.open(output_file, \"w\", \"utf-8\")\n",
    "split = text.split(\"\\w\")\n",
    "for s in split:\n",
    "    print(s)\n",
    "    output.write(s+\"\\r\\n\\r\\n\")    \n",
    "output.close()\n",
    "print(\"Your file has been exported to \"+output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "You've reached the end of Chapter 5! You can safely ignore the code below, it's only there to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When you make the exercises below, don't write your code in the IPython notebook anymore but write in a separate file and run them from the command line!**\n",
    "\n",
    "Inspired by *Think Python* by Allen B. Downey (http://thinkpython.com), *Introduction to Programming Using Python* by Y. Liang (Pearson, 2013). Some exercises below have been taken from: http://www.ling.gu.se/~lager/python_exercises.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `dice.py`: write a script that rolls a dice every time you run it, by generating and printing a random integer between 1 and 6! You can import functionality for doing this via `random.randint()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  `arithmetic.py`: define a function add() and a function multiply() that sums and multiplies (respectively) all the numbers in a list of numbers. For example, add([1, 2, 3, 4]) should return 10, and multiply([1, 2, 3, 4]) should return 24.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  `anagram.py`: two words are anagrams if you can rearrange the letters from one to spell the other. Write a function called is_anagram that takes two strings and returns True if they are anagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  `hapax1.py`: a *hapax legomenon* (often abbreviated to hapax) is a word which occurs only once in either the written record of a language, the works of an author, or in a single text. Define a function `legomena` that given the filename of a text will return a list of all its hapax legomena. Make sure your program ignores capitalization as well as punctuation (hint: check out `string.punctuation` online!). Try out the function on your Gutenberg book from the previous Chapter. For simplicity, make sure your Gutenberg file is in the same directory as your hapax script, so that you can just use the file's name as a relative path. Alternatively, you can use an absolute path to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hapax2.py`: copy `hapax1.py` and try to move well-defined steps from your `legomena` function (reading and cleaning the input text, making a frequency dictionary) into separate functions, which are then called in the `legomena` function. This is called *code refactoring*: splitting multi-step functionality over several functions. This is good practice, and will make the next exercise much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `hapax3.py`: copy `hapax2.py` and create two additional functions: one that spots hapax `dislegomena` (words occuring only twice) and one that spots hapax `trislegomena` (words occuring only three times) in a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `calling_hapax.py`: in this standalone script, import the functions from `hapax3.py` and call all three functions from there. Again, try them out on your Gutenberg-file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "You've reached the end of Chapter 6! You can safely ignore the code below, it's only there to make the page pretty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"styles/custom.css\", \"r\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "_joined"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
